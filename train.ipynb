{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BHZnXywjxGeq"
      },
      "outputs": [],
      "source": [
        "#https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kY_j8RUDP5y4"
      },
      "outputs": [],
      "source": [
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import math\n",
        "from torch.autograd.variable import Variable\n",
        "import typing\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph2WO5JpKukk",
        "outputId": "4364d3af-8649-4bfa-c009-1e1b5b20918f"
      },
      "outputs": [],
      "source": [
        "prefix='/home/ericbuehler/english-transformer'\n",
        "prefix_='/home/ericbuehler/english-transformer'\n",
        "modelname=\"4_14_23_m3\"\n",
        "\n",
        "prefix_models=prefix+\"/models/\"+modelname+\"/\"\n",
        "\n",
        "if not os.path.exists(prefix_models):\n",
        "    os.makedirs(prefix_models)\n",
        "            \n",
        "os.chdir(prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xGOoJdNdRSaO"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XakHZ4HfFdYM"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        key_tp = key.transpose(-2, -1)\n",
        "\n",
        "        scores = query.matmul(key_tp) / math.sqrt(query.size()[-1])\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "            \n",
        "        attention = F.softmax(scores, dim = -1)\n",
        "\n",
        "        return attention.matmul(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G-sb6gd7L5bR"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_features,\n",
        "                 head_num,\n",
        "                 bias=True,\n",
        "                 activation=F.relu):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        if in_features % head_num != 0:\n",
        "            raise ValueError('`in_features`({}) should be divisible by \\\n",
        "                `head_num`({})'.format(in_features, head_num))\n",
        "        self.in_features = in_features\n",
        "        self.head_num = head_num\n",
        "        self.activation = activation\n",
        "        self.bias = bias\n",
        "        self.linear_q = nn.Linear(in_features, in_features, bias)\n",
        "        self.linear_k = nn.Linear(in_features, in_features, bias)\n",
        "        self.linear_v = nn.Linear(in_features, in_features, bias)\n",
        "        self.linear_o = nn.Linear(in_features, in_features, bias)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        q, k, v = self.linear_q(q), self.linear_k(k), self.linear_v(v)\n",
        "        if self.activation is not None:\n",
        "            q = self.activation(q)\n",
        "            k = self.activation(k)\n",
        "            v = self.activation(v)\n",
        "\n",
        "        q = self._reshape_to_batches(q)\n",
        "        k = self._reshape_to_batches(k)\n",
        "        v = self._reshape_to_batches(v)\n",
        "        \n",
        "        if mask is not None:\n",
        "            mask = mask.repeat(self.head_num, 1, 1)   \n",
        "        \n",
        "        y = ScaledDotProductAttention()(q, k, v, mask)        \n",
        "        \n",
        "        y = self._reshape_from_batches(y)      \n",
        "\n",
        "        y = self.linear_o(y)\n",
        "        if self.activation is not None:\n",
        "            y = self.activation(y)\n",
        "        return y\n",
        "\n",
        "    @staticmethod\n",
        "    def gen_causal_mask(x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        return torch.tril(torch.ones(seq_len, seq_len)).view(1, seq_len, seq_len).repeat(batch_size, 1, 1)\n",
        "\n",
        "    def _reshape_to_batches(self, x):\n",
        "        batch_size, seq_len, in_feature = x.size()\n",
        "        sub_dim = in_feature // self.head_num\n",
        "        return x.reshape(batch_size, seq_len, self.head_num, sub_dim)\\\n",
        "                .permute(0, 2, 1, 3)\\\n",
        "                .reshape(batch_size * self.head_num, seq_len, sub_dim)\n",
        "\n",
        "    def _reshape_from_batches(self, x):\n",
        "        batch_size, seq_len, in_feature = x.size()\n",
        "        batch_size //= self.head_num\n",
        "        out_dim = in_feature * self.head_num\n",
        "        return x.reshape(batch_size, self.head_num, seq_len, in_feature)\\\n",
        "                .permute(0, 2, 1, 3)\\\n",
        "                .reshape(batch_size, seq_len, out_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NDpTASiaTxTX"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 embedding_dim,\n",
        "                 n_heads,\n",
        "                 n_features):\n",
        "        super().__init__()\n",
        "        self.multi1 = MultiHeadAttention(embedding_dim, n_heads)\n",
        "        self.multi2 = MultiHeadAttention(embedding_dim, n_heads)\n",
        "        self.multi3 = MultiHeadAttention(embedding_dim, n_heads)\n",
        "        self.embedding = nn.Embedding(n_features, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.embedding(x.long())\n",
        "        x1 = self.multi1(x0,x0,x0)\n",
        "        x2 = self.multi1(x1,x1,x1)\n",
        "        x3 = self.multi1(x2,x2,x2)\n",
        "        return x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HqGGEpvCLbP8"
      },
      "outputs": [],
      "source": [
        "def tokenize_multi(text_seq: str, features: int, encoding = \"utf8\") -> torch.Tensor:\n",
        "    # tokenize the input text\n",
        "    sentences = []\n",
        "    for sentence in filter(lambda x: x!=\"\", text_seq.split(\"\\n\")):\n",
        "        base = list(bytes(sentence, \"utf8\"))\n",
        "        if len(base) < features:\n",
        "            base.extend([0] * (features - len(base)))\n",
        "        tensor = torch.Tensor(base)\n",
        "        tensor = tensor.unsqueeze(0)\n",
        "        sentences.append(tensor)\n",
        "\n",
        "    return torch.cat(sentences, dim = 0)\n",
        "\n",
        "def tokenize_single(sentence: str, features: int, encoding = \"utf8\") -> torch.Tensor:\n",
        "    base = list(bytes(sentence, \"utf8\"))\n",
        "    if len(base) < features:\n",
        "        base.extend([0] * (features - len(base)))\n",
        "    tensor = torch.Tensor(base)\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R81mAag8mHEG"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data: typing.List[str], features):\n",
        "        self.raw_data = data\n",
        "        self.features = features\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.raw_data)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return tokenize_single(self.raw_data[index], self.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "97rbDfS4gO8C"
      },
      "outputs": [],
      "source": [
        "n_features = 262 # I know this is the largest\n",
        "embedding_dim = 384\n",
        "train_split = 0.9\n",
        "batch_size = 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IvvenMeUKfaj"
      },
      "outputs": [],
      "source": [
        "path_to_data = \"data/english.txt\"\n",
        "data_raw = open(path_to_data, encoding=\"utf-8\").read()\n",
        "\n",
        "data_split = list(filter(lambda x: x!=\"\", data_raw.split(\"\\n\")))\n",
        "random.shuffle(data_split)\n",
        "\n",
        "n = int(train_split * len(data_split))\n",
        "train_data = data_split[:n]\n",
        "val_data = data_split[n:]\n",
        "\n",
        "train_dataloader = TextDataset(train_data, n_features)\n",
        "test_dataloader = TextDataset(train_data, n_features)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(train_dataloader, batch_size=batch_size)\n",
        "testloader = torch.utils.data.DataLoader(test_dataloader , batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvibftHanb0A",
        "outputId": "fcee2d44-26ea-4965-844b-4e1d9cb8b1e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 262, 384])\n"
          ]
        }
      ],
      "source": [
        "model = Transformer(embedding_dim, 4, n_features)\n",
        "res = model(next(iter(testloader)))\n",
        "print(res.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
